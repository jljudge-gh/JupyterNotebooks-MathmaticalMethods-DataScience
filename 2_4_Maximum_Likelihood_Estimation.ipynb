{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2.4 Maximum Likelihood Estimation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMniqRvDHNN75+VtQ0LBdv7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jljudge-gh/JupyterNotebooks-MathmaticalMethods-DataScience/blob/main/2_4_Maximum_Likelihood_Estimation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5SkSZDw2l_LJ"
      },
      "source": [
        "# 2.4 Maximum Likelihood Estimation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8sX2dDKl_X9"
      },
      "source": [
        "## 2.4.1 MLE for Random Samples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A3Wq84tzmAqI"
      },
      "source": [
        "Maximum likelihood estimation (MLE) is an effective approach of estimating the parameters of a probability distribution through maximizing a likelihood function. The point in the parameter space that maximizes the likelihood function is called the maximum likelihood estimate. The logic of maximum likelihood is both intuitive and flexible. As a result, the method has become a dominant means of statistical inference\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKFwI2UNmNJk"
      },
      "source": [
        "### Definition 2.4.1\n",
        "Let $X_{1}, X_{2}, \\ldots, X_{n}$ have joint $\\mathrm{pmf}$ or pdf\n",
        "$$\n",
        "f\\left(x_{1}, x_{2}, \\ldots, x_{n} ; \\theta_{1}, \\ldots, \\theta_{m}\\right)\n",
        "$$\n",
        "where the parameters $\\theta_{1}, \\ldots, \\theta_{m}$ have unknown values. When $x_{1}, \\ldots, x_{n}$ are the observed sample values and (2.4.1) is regarded as a function of $\\theta_{1}, \\ldots, \\theta_{m}$, it is called the likelihood function. The maximum likelihood estimates (mle's) $\\hat{\\theta}_{1}, \\ldots, \\hat{\\theta}_{m}$ are those values of the $\\theta_{i}$ 's that maximize the likelihood function, so that\n",
        "$$\n",
        "f\\left(x_{1}, \\ldots, x_{n} ; \\hat{\\theta}_{1}, \\ldots, \\hat{\\theta}_{m}\\right) \\geq f\\left(x_{1}, \\ldots, x_{n} ; \\theta_{1}, \\ldots, \\theta_{m}\\right) \\text { for all } \\theta_{1}, \\ldots, \\theta_{m}\n",
        "$$\n",
        "When the $X_{i}$ 's are substituted in place of the $x_{i}$ 's, the maximum likelihood estimators result."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBpVunqTmTO-"
      },
      "source": [
        "## 2.4.2 Linear Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhY5gZmJmTRc"
      },
      "source": [
        "Given input data points $\\left\\{\\left(\\mathbf{x}_{i}, y_{i}\\right)\\right\\}_{i=1}^{n}$, we seek an affine function to fit the data and each $\\mathbf{x}_{i}=\\left(x_{i 1}, \\ldots, x_{i p}\\right)$. The common approach involves finding coefficients $\\beta_{j}, j=1 \\ldots, p$ 's that minimize the criterion\n",
        "$$\n",
        "\\sum_{i=1}^{n}\\left(y_{i}-\\hat{y}_{i}\\right)^{2}\n",
        "$$\n",
        "where\n",
        "$$\n",
        "\\hat{y}_{i}=\\beta_{0}+\\beta_{1} x_{i 1}+\\ldots+\\beta_{p} x_{i p}\n",
        "$$\n",
        "Now we wish to discuss it from a probabilistic point of view by the maximum likelihood estimation. Consider that we have $n$ points, each of which is drawn in an independent and identically distributed (i.i.d.) way from the normal distribution. For a given, $\\mu, \\sigma^{2}$, the probability of those $n$ points being drawn define the likelihood function, which are just the multiplication of $n$ normal probability density functions (pdf) (because they are independent).\n",
        "$$\n",
        "\\mathscr{P}(\\mu \\mid y)=\\prod_{i=1}^{n} P_{Y}\\left(y_{i} \\mid \\mu, \\sigma^{2}\\right)=\\prod_{i=1}^{n} \\frac{1}{\\sigma \\sqrt{2 \\pi}} e^{-\\frac{\\left(y_{i}-\\mu\\right)^{2}}{2 \\sigma^{2}}}\n",
        "$$\n",
        "Now understand that $y$ is a random variable.\n",
        "$$\n",
        "y_{i}=\\hat{y}_{i}+\\varepsilon\n",
        "$$\n",
        "where $\\varepsilon \\sim N\\left(0, \\sigma^{2}\\right)$. Thus, $y_{i}$ is a normal variable with mean as a linear function of $\\mathbf{x}$ and a fixed standard deviation:\n",
        "$$\n",
        "y_{i} \\sim N\\left(\\hat{y}_{i}, \\sigma^{2}\\right)\n",
        "$$\n",
        "As a result, for each $y_{i}$, we choose $\\mu$ in the normal distributions in (2.4.2) as\n",
        "$$\n",
        "\\mu_{i}=\\hat{y}_{i}\n",
        "$$\n",
        "Hence we derive the maximum likelihood estimate\n",
        "$$\n",
        "\\begin{aligned}\n",
        "\\hat{\\beta}=\\arg \\max \\mathscr{P}(\\beta \\mid y) &=\\arg \\max _{\\beta} \\prod_{i=1}^{n} \\frac{1}{\\sigma \\sqrt{2 \\pi}} e^{-\\frac{\\left(y_{i}-\\hat{y}_{i}\\right)^{2}}{2 \\sigma^{2}}} \\\\\n",
        "&=\\arg \\max _{\\beta} \\log \\left(\\prod_{i=1}^{n} \\frac{1}{\\sigma \\sqrt{2 \\pi}} e^{\\left.-\\frac{\\left(y_{i}-\\hat{y}_{i}\\right)^{2}}{2 \\sigma^{2}}\\right)}\\right.\\\\\n",
        "&=\\arg \\max _{\\beta} \\sum_{i=1}^{n} \\log \\left(\\frac{1}{\\sigma \\sqrt{2 \\pi}}\\right)+\\log \\left(e^{\\left.-\\frac{\\left(y_{i}-\\hat{y}_{i}\\right)^{2}}{2 \\sigma^{2}}\\right)}\\right.\\\\\n",
        "&=\\arg \\max _{\\beta} \\sum_{i=1}^{n} \\log \\left(e^{\\left.-\\frac{\\left(y_{i}-\\hat{y}_{i}\\right)^{2}}{2 \\sigma^{2}}\\right)}\\right.\\\\\n",
        "&=\\arg \\max _{\\beta} \\sum_{i=1}^{n}-\\frac{\\left(y_{i}-\\hat{y}_{i}\\right)^{2}}{2 \\sigma^{2}} \\\\\n",
        "&=\\arg \\min _{\\beta} \\sum_{i=1}^{n}\\left(y_{i}-\\hat{y}_{i}\\right)^{2}\n",
        "\\end{aligned}\n",
        "$$\n",
        "which is exactly the least square problem we discussed before."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hECSNMNnj73"
      },
      "source": [
        "## Maximum Likelihood Estimation in Python "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3KOfGR5knwT_"
      },
      "source": [
        "Here, we perform simple linear regression on synthetic data. The data is ensured to be normally distributed by incorporating some random Gaussian noises. Data can be said to be normally distributed if its residual follows the normal distribution—Import the necessary libraries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTXYdIUxnxQu"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "from statsmodels import api\n",
        "from scipy import stats\n",
        "from scipy.optimize import minimize "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "gUPyg44unxXB",
        "outputId": "dc7c4700-98a5-471f-b793-53fc7f8584f8"
      },
      "source": [
        "# generate an independent variable \n",
        "x = np.linspace(-10, 30, 100)\n",
        "# generate a normally distributed residual\n",
        "e = np.random.normal(10, 5, 100)\n",
        "# generate ground truth\n",
        "y = 10 + 4*x + e\n",
        "df = pd.DataFrame({'x':x, 'y':y})\n",
        "df.head() "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-14.899883</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-9.595960</td>\n",
              "      <td>-22.827566</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-9.191919</td>\n",
              "      <td>-15.686805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-8.787879</td>\n",
              "      <td>-22.069221</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-8.383838</td>\n",
              "      <td>-6.485108</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           x          y\n",
              "0 -10.000000 -14.899883\n",
              "1  -9.595960 -22.827566\n",
              "2  -9.191919 -15.686805\n",
              "3  -8.787879 -22.069221\n",
              "4  -8.383838  -6.485108"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "fV14VN_en2l_",
        "outputId": "89838ffd-44d0-4f7a-9e05-4474737c0465"
      },
      "source": [
        "sns.regplot(x='x', y='y', data = df)\n",
        "plt.show() "
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iY265BETn6kJ"
      },
      "source": [
        "The data is normally distributed, and the output variable is a continuously varying number. Hence, we can use the Ordinary Least Squares (OLS) method to determine the model parameters and use them as a benchmark to evaluate the Maximum Likelihood Estimation approach. Apply the OLS algorithm to the synthetic data and find the model parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "G4PZmc8dn4bY",
        "outputId": "76f79d26-9b44-4129-b822-17b0c05fae11"
      },
      "source": [
        " features = api.add_constant(df.x)\n",
        " model = api.OLS(y, features).fit()\n",
        " model.summary() "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>OLS Regression Results</caption>\n",
              "<tr>\n",
              "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.985</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.985</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   6553.</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Date:</th>             <td>Mon, 27 Sep 2021</td> <th>  Prob (F-statistic):</th> <td>1.43e-91</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Time:</th>                 <td>00:20:53</td>     <th>  Log-Likelihood:    </th> <td> -315.28</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>No. Observations:</th>      <td>   100</td>      <th>  AIC:               </th> <td>   634.6</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Residuals:</th>          <td>    98</td>      <th>  BIC:               </th> <td>   639.8</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>const</th> <td>   20.6409</td> <td>    0.753</td> <td>   27.396</td> <td> 0.000</td> <td>   19.146</td> <td>   22.136</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x</th>     <td>    3.9700</td> <td>    0.049</td> <td>   80.952</td> <td> 0.000</td> <td>    3.873</td> <td>    4.067</td>\n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "  <th>Omnibus:</th>       <td> 1.644</td> <th>  Durbin-Watson:     </th> <td>   1.850</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Prob(Omnibus):</th> <td> 0.440</td> <th>  Jarque-Bera (JB):  </th> <td>   1.693</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Skew:</th>          <td>-0.268</td> <th>  Prob(JB):          </th> <td>   0.429</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Kurtosis:</th>      <td> 2.655</td> <th>  Cond. No.          </th> <td>    20.3</td>\n",
              "</tr>\n",
              "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
            ],
            "text/plain": [
              "<class 'statsmodels.iolib.summary.Summary'>\n",
              "\"\"\"\n",
              "                            OLS Regression Results                            \n",
              "==============================================================================\n",
              "Dep. Variable:                      y   R-squared:                       0.985\n",
              "Model:                            OLS   Adj. R-squared:                  0.985\n",
              "Method:                 Least Squares   F-statistic:                     6553.\n",
              "Date:                Mon, 27 Sep 2021   Prob (F-statistic):           1.43e-91\n",
              "Time:                        00:20:53   Log-Likelihood:                -315.28\n",
              "No. Observations:                 100   AIC:                             634.6\n",
              "Df Residuals:                      98   BIC:                             639.8\n",
              "Df Model:                           1                                         \n",
              "Covariance Type:            nonrobust                                         \n",
              "==============================================================================\n",
              "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
              "------------------------------------------------------------------------------\n",
              "const         20.6409      0.753     27.396      0.000      19.146      22.136\n",
              "x              3.9700      0.049     80.952      0.000       3.873       4.067\n",
              "==============================================================================\n",
              "Omnibus:                        1.644   Durbin-Watson:                   1.850\n",
              "Prob(Omnibus):                  0.440   Jarque-Bera (JB):                1.693\n",
              "Skew:                          -0.268   Prob(JB):                        0.429\n",
              "Kurtosis:                       2.655   Cond. No.                         20.3\n",
              "==============================================================================\n",
              "\n",
              "Warnings:\n",
              "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
              "\"\"\""
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nFokSe2oAbP"
      },
      "source": [
        "We get the intercept and regression coefficient values of the simple linear regression model. Further, we can derive the standard deviation of the normal distribution with the following codes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B81vVeMuoBE4",
        "outputId": "a585f941-065e-4883-981b-2e4f1522aee0"
      },
      "source": [
        "res = model.resid\n",
        "standard_dev = np.std(res)\n",
        "standard_dev "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5.662206074008264"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wuW3OxOtoH2q"
      },
      "source": [
        "As we have solved the simple linear regression problem with an OLS model, it is time to solve the same problem by formulating it with Maximum Likelihood Estimation.\n",
        "\n",
        "Define a user-defined Python function that can be iteratively called to determine the negative log-likelihood value. The key idea of formulating this function is that it must contain two elements: the first is the model building equation (here, the simple linear regression). The second is the logarithmic value of the probability density function (here, the log PDF of normal distribution). Since we need negative log-likelihood, it is obtained just by negating the log-likelihood."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIfYo6RUoH9x"
      },
      "source": [
        "# MLE function\n",
        "# ml modeling and neg LL calculation\n",
        "def MLE_Norm(parameters):\n",
        "  # extract parameters\n",
        "  const, beta, std_dev = parameters\n",
        "  # predict the output\n",
        "  pred = const + beta*x\n",
        "  # Calculate the log-likelihood for normal distribution\n",
        "  LL = np.sum(stats.norm.logpdf(y, pred, std_dev))\n",
        "  # Calculate the negative log-likelihood\n",
        "  neg_LL = -1*LL\n",
        "  return neg_LL "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zaZE0k9toMln"
      },
      "source": [
        "Minimize the negative log-likelihood of the generated data using the minimize method available with SciPy’s optimize module."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qX3z9aaoMrX",
        "outputId": "e8c202fa-25ab-4ebd-b279-d89f1191fee5"
      },
      "source": [
        "# minimize arguments: function, intial_guess_of_parameters, method\n",
        "mle_model = minimize(MLE_Norm, np.array([2,2,2]), method='L-BFGS-B')\n",
        "mle_model "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      fun: 315.2752115206695\n",
              " hess_inv: <3x3 LbfgsInvHessProduct with dtype=float64>\n",
              "      jac: array([ 0.00000000e+00, -2.27373675e-05, -5.68434189e-06])\n",
              "  message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
              "     nfev: 224\n",
              "      nit: 29\n",
              "   status: 0\n",
              "  success: True\n",
              "        x: array([20.6409492 ,  3.96998102,  5.66220544])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfnLTPROoMza"
      },
      "source": [
        "The MLE approach arrives at the final optimal solution after 35 iterations. The model’s parameters, the intercept, the regression coefficient and the standard deviation are well matching to those obtained using the OLS approach. \n",
        "\n",
        "[Source](https://analyticsindiamag.com/maximum-likelihood-estimation-python-guide/)"
      ]
    }
  ]
}